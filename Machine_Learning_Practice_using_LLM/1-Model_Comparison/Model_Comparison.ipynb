{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_comparison_rmse.py\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# XGBoost (may require installation)\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "except Exception as e:\n",
    "    raise ImportError(\"Please install xgboost first: pip install xgboost\") from e\n",
    "\n",
    "# =======================\n",
    "# Parameters (modifiable)\n",
    "# =======================\n",
    "DATA_FILE = \"Data.xlsx\"            # Input file (in the same directory)\n",
    "TARGET_COL = \"Hv\"                  # Target column name\n",
    "N_SPLITS = 5                       # 5-fold CV\n",
    "N_REPEATS = 20                     # Repeat 20 times\n",
    "RANDOM_STATE_BASE = 42             # Base random seed (different seed for each repetition)\n",
    "\n",
    "OUT_CSV = \"Model_Comparison_RMSE.csv\"\n",
    "OUT_PNG = \"Model_Comparison_RMSE.png\"\n",
    "\n",
    "# =======================\n",
    "# Read data\n",
    "# =======================\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    raise FileNotFoundError(f\"Cannot find {DATA_FILE}. Please put Data.xlsx in the same directory as this script and ensure the first column name is '{TARGET_COL}'.\")\n",
    "\n",
    "df = pd.read_excel(DATA_FILE)\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET_COL}' not found in data. Use df.columns to check column names.\")\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL]).values\n",
    "y = df[TARGET_COL].values\n",
    "\n",
    "# =======================\n",
    "# Define model dictionary\n",
    "# =======================\n",
    "models = {\n",
    "    \"GDB\": GradientBoostingRegressor(random_state=RANDOM_STATE_BASE),\n",
    "    \"RF\": RandomForestRegressor(n_estimators=200, random_state=RANDOM_STATE_BASE, n_jobs=-1),\n",
    "    \"XGB\": XGBRegressor(n_estimators=200, random_state=RANDOM_STATE_BASE, verbosity=0),\n",
    "    \"ADB\": AdaBoostRegressor(random_state=RANDOM_STATE_BASE),\n",
    "    \"DT\": DecisionTreeRegressor(random_state=RANDOM_STATE_BASE),\n",
    "    \"SVM-lin\": SVR(kernel=\"linear\"),\n",
    "    \"SVM-poly\": SVR(kernel=\"poly\", degree=3),\n",
    "    \"SVM-rbf\": SVR(kernel=\"rbf\"),\n",
    "    \"KNN\": KNeighborsRegressor(n_neighbors=5, n_jobs=-1),\n",
    "    \"MLP\": MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=RANDOM_STATE_BASE)\n",
    "}\n",
    "\n",
    "# Build pipeline for models requiring standardization (e.g., linear/SVM/KNN/MLP)\n",
    "# We apply a consistent rule: use StandardScaler for non-tree models (more stable)\n",
    "def make_pipeline(model):\n",
    "    # For tree-based models (RF, GDB, XGB, ADB, DT), scaling is not necessary, but harmless\n",
    "    name = model.__class__.__name__.lower()\n",
    "    if isinstance(model, (RandomForestRegressor, GradientBoostingRegressor, XGBRegressor, AdaBoostRegressor, DecisionTreeRegressor)):\n",
    "        return Pipeline([(\"model\", model)])\n",
    "    else:\n",
    "        return Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
    "\n",
    "# =======================\n",
    "# Main loop: Repeat N_REPEATS times, each with a different random seed for KFold\n",
    "# =======================\n",
    "results = {name: [] for name in models.keys()}\n",
    "\n",
    "for rep in range(N_REPEATS):\n",
    "    seed = RANDOM_STATE_BASE + rep  # Different random seed each time\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=seed)\n",
    "    print(f\"Repetition {rep+1}/{N_REPEATS}  (seed={seed})\")\n",
    "\n",
    "    for name, base_model in models.items():\n",
    "        pipeline = make_pipeline(base_model)\n",
    "        # Use negative mean squared error as the scoring metric (cross_val_score returns negative values)\n",
    "        # Convert to positive and take the square root to obtain RMSE for each fold\n",
    "        scores = cross_val_score(pipeline, X, y, cv=kf, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "        rmse_folds = np.sqrt(-scores)             # RMSE per fold\n",
    "        mean_rmse = rmse_folds.mean()             # Mean RMSE across 5 folds for this repetition\n",
    "        results[name].append(mean_rmse)\n",
    "\n",
    "# =======================\n",
    "# Summary: compute mean and std across 20 repetitions\n",
    "# =======================\n",
    "summary_rows = []\n",
    "for name, vals in results.items():\n",
    "    vals = np.array(vals)\n",
    "    mean_all = vals.mean()\n",
    "    std_all = vals.std(ddof=1)\n",
    "    summary_rows.append({\n",
    "        \"model\": name,\n",
    "        \"mean_RMSE\": mean_all,\n",
    "        \"std_RMSE\": std_all,\n",
    "        \"all_repetition_RMSEs\": \",\".join([f\"{v:.6f}\" for v in vals])\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(\"mean_RMSE\").reset_index(drop=True)\n",
    "\n",
    "# Save CSV (includes RMSEs from all repetitions)\n",
    "summary_df.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ Evaluation results saved as: {OUT_CSV}\")\n",
    "\n",
    "# =======================\n",
    "# Plot: bar chart with error bars\n",
    "# =======================\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_pos = np.arange(len(summary_df))\n",
    "means = summary_df[\"mean_RMSE\"].values\n",
    "stds = summary_df[\"std_RMSE\"].values\n",
    "\n",
    "bars = plt.bar(x_pos, means, yerr=stds, capsize=6)\n",
    "plt.xticks(x_pos, summary_df[\"model\"], rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(f\"Model comparison (RMSE) — {N_SPLITS}-fold CV × {N_REPEATS} repeats\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_PNG, dpi=300)\n",
    "plt.show()\n",
    "print(f\"✅ Comparison plot saved as: {OUT_PNG}\")\n",
    "\n",
    "# =======================\n",
    "# Save a more detailed result (each repetition as a column)\n",
    "# =======================\n",
    "# Build DataFrame: rows = models, columns = rep_1 ... rep_N, plus mean and std\n",
    "detailed = []\n",
    "for name, vals in results.items():\n",
    "    row = {\"model\": name}\n",
    "    for i, v in enumerate(vals, 1):\n",
    "        row[f\"rep_{i}\"] = v\n",
    "    row[\"mean_RMSE\"] = np.mean(vals)\n",
    "    row[\"std_RMSE\"] = np.std(vals, ddof=1)\n",
    "    detailed.append(row)\n",
    "\n",
    "detailed_df = pd.DataFrame(detailed).set_index(\"model\")\n",
    "detailed_df.to_excel(\"Model_Comparison_Detailed_RMSE.xlsx\")\n",
    "print(\"✅ Detailed results saved as: Model_Comparison_Detailed_RMSE.xlsx\")\n",
    "\n",
    "# =======================\n",
    "# Print summary (concise)\n",
    "# =======================\n",
    "print(\"\\n=== Summary (ordered by mean_RMSE) ===\")\n",
    "print(summary_df[[\"model\", \"mean_RMSE\", \"std_RMSE\"]].to_string(index=False, float_format='%.6f'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
