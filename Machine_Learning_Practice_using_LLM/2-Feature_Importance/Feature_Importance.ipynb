{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8bccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance_gdb.py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===============================\n",
    "# Parameter Settings\n",
    "# ===============================\n",
    "DATA_FILE = \"Data.xlsx\"\n",
    "TARGET_COL = \"Hv\"\n",
    "N_SPLITS = 5\n",
    "N_REPEATS = 10\n",
    "RANDOM_BASE = 42\n",
    "\n",
    "OUT_CSV = \"Feature_Importance_GDB.csv\"\n",
    "OUT_PNG = \"Feature_Importance_GDB.png\"\n",
    "\n",
    "# ===============================\n",
    "# Step 1. Load Data\n",
    "# ===============================\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    raise FileNotFoundError(f\"‚ùå File not found: {DATA_FILE}\")\n",
    "\n",
    "df = pd.read_excel(DATA_FILE)\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"‚ùå Target column '{TARGET_COL}' not found in data.\")\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL].values\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# ===============================\n",
    "# Step 2. Initialize Model and Scaler\n",
    "# ===============================\n",
    "base_model = GradientBoostingRegressor(random_state=RANDOM_BASE)\n",
    "model = Pipeline([(\"scaler\", StandardScaler()), (\"gdb\", base_model)])\n",
    "\n",
    "# ===============================\n",
    "# Step 3. Multiple Repeats + Cross-Validation + Permutation Importance\n",
    "# ===============================\n",
    "all_importances = pd.DataFrame(0, index=feature_names, columns=[f\"rep_{i+1}\" for i in range(N_REPEATS)])\n",
    "all_rmse = []\n",
    "\n",
    "for rep in range(N_REPEATS):\n",
    "    print(f\"üîÅ Evaluation {rep+1}/{N_REPEATS} in progress...\")\n",
    "\n",
    "    # Use different random seeds for different splits\n",
    "    seed = RANDOM_BASE + rep\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Fit model and calculate cross-validation RMSE\n",
    "    scores = cross_val_score(model, X, y, cv=kf, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "    rmse_mean = np.sqrt(-scores).mean()\n",
    "    all_rmse.append(rmse_mean)\n",
    "\n",
    "    # Retrain model on full data (for feature importance calculation)\n",
    "    model.fit(X, y)\n",
    "    r = permutation_importance(model, X, y, scoring=\"neg_mean_squared_error\", n_repeats=10, random_state=seed)\n",
    "    # Take the average importance values\n",
    "    importances = np.mean(r.importances, axis=1)\n",
    "    all_importances[f\"rep_{rep+1}\"] = importances\n",
    "\n",
    "# ===============================\n",
    "# Step 4. Compute Average Results\n",
    "# ===============================\n",
    "all_importances[\"mean_importance\"] = all_importances.mean(axis=1)\n",
    "all_importances[\"std_importance\"] = all_importances.std(axis=1)\n",
    "all_importances = all_importances.sort_values(\"mean_importance\", ascending=False)\n",
    "\n",
    "# Save results\n",
    "all_importances.to_csv(OUT_CSV, encoding=\"utf-8-sig\")\n",
    "print(f\"‚úÖ Feature importance results saved as: {OUT_CSV}\")\n",
    "\n",
    "# ===============================\n",
    "# Step 5. Plot\n",
    "# ===============================\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(all_importances.index, all_importances[\"mean_importance\"], xerr=all_importances[\"std_importance\"], capsize=5)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Feature Importance (average over 10 repeats)\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importance (Gradient Boosting, 5-fold CV √ó 10 repeats)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_PNG, dpi=300)\n",
    "plt.show()\n",
    "print(f\"‚úÖ Plot saved as: {OUT_PNG}\")\n",
    "\n",
    "# ===============================\n",
    "# Step 6. Print Summary\n",
    "# ===============================\n",
    "print(\"\\n=== Average Feature Importance Ranking ===\")\n",
    "print(all_importances[[\"mean_importance\", \"std_importance\"]].to_string(float_format=\"%.6f\"))\n",
    "\n",
    "print(f\"\\nüìâ Average RMSE (mean over 10 repeats): {np.mean(all_rmse):.4f} ¬± {np.std(all_rmse):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
