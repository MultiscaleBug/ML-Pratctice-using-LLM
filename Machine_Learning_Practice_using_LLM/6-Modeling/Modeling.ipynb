{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gdb_top9.py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------------------------\n",
    "# File paths & parameters\n",
    "# ----------------------------\n",
    "DATA_FILE = \"Data.xlsx\"                          # Original dataset (first column: Hv)\n",
    "RANKING_CSV = \"Selected_Feature_Ranking.csv\"    # Primary source (should include 'feature' or similar column)\n",
    "IMP_CSV = \"Feature_Importance_GDB.csv\"          # Secondary source\n",
    "PCC_XLSX = \"Selected_Features_PCC.xlsx\"         # Fallback source (columns are remaining features)\n",
    "\n",
    "TOP_K = 9\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "CV_FOLDS = 5\n",
    "\n",
    "OUT_MODEL = \"GDB_top9_model.pkl\"\n",
    "OUT_METRICS = \"GDB_top9_metrics.csv\"\n",
    "OUT_PREDICTIONS = \"GDB_top9_predictions.csv\"\n",
    "OUT_PARITY = \"GDB_top9_parity.png\"\n",
    "OUT_R2BAR = \"GDB_top9_r2bar.png\"\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Load data\n",
    "# ----------------------------\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    raise FileNotFoundError(f\"❌ File not found: {DATA_FILE}. Please ensure it is in the same directory as the script.\")\n",
    "\n",
    "df = pd.read_excel(DATA_FILE)\n",
    "\n",
    "if \"Hv\" not in df.columns:\n",
    "    raise ValueError(f\"❌ Target column 'Hv' not found. Please make sure the target column is named 'Hv'. \"\n",
    "                     f\"Current columns: {list(df.columns)}\")\n",
    "\n",
    "X_all = df.drop(columns=[\"Hv\"])\n",
    "y_all = df[\"Hv\"].values\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Select top 9 features (multiple sources)\n",
    "# ----------------------------\n",
    "selected_features = None\n",
    "\n",
    "# Priority 1: Selected_Feature_Ranking.csv\n",
    "if os.path.exists(RANKING_CSV):\n",
    "    try:\n",
    "        tmp = pd.read_csv(RANKING_CSV, encoding=\"utf-8-sig\")\n",
    "        feature_col_candidates = [c for c in tmp.columns if c.lower() in (\"feature\", \"feature_name\", \"name\")]\n",
    "        feature_col = feature_col_candidates[0] if feature_col_candidates else tmp.columns[0]\n",
    "        top_list = tmp[feature_col].astype(str).tolist()\n",
    "        selected_features = [f for f in top_list if f in X_all.columns][:TOP_K]\n",
    "        print(f\"Loaded {len(selected_features)} matching features from {RANKING_CSV} (top {TOP_K} used).\")\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Failed to read Selected_Feature_Ranking.csv, trying next source.\", e)\n",
    "\n",
    "# Priority 2: Feature_Importance_GDB.csv\n",
    "if (selected_features is None or len(selected_features) < TOP_K) and os.path.exists(IMP_CSV):\n",
    "    try:\n",
    "        tmp = pd.read_csv(IMP_CSV, encoding=\"utf-8-sig\")\n",
    "        feat_cands = [c for c in tmp.columns if c.lower() in (\"feature\", \"index\", \"unnamed: 0\")]\n",
    "        imp_cands = [c for c in tmp.columns if c.lower() in (\"mean_importance\", \"importance\", \"score\", \"mean_score\")]\n",
    "        feat_col = feat_cands[0] if feat_cands else tmp.columns[0]\n",
    "        imp_col = imp_cands[0] if imp_cands else (tmp.columns[1] if tmp.shape[1] > 1 else tmp.columns[0])\n",
    "        tmp2 = tmp[[feat_col, imp_col]].rename(columns={feat_col: \"feature\", imp_col: \"importance\"})\n",
    "        tmp2[\"feature\"] = tmp2[\"feature\"].astype(str)\n",
    "        tmp2 = tmp2.sort_values(\"importance\", ascending=False)\n",
    "        ranked = [f for f in tmp2[\"feature\"].tolist() if f in X_all.columns]\n",
    "        if selected_features is None:\n",
    "            selected_features = ranked[:TOP_K]\n",
    "        else:\n",
    "            for f in ranked:\n",
    "                if f not in selected_features and len(selected_features) < TOP_K:\n",
    "                    selected_features.append(f)\n",
    "        print(f\"After adding from {IMP_CSV}, total selected features: {len(selected_features)} (target {TOP_K}).\")\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Failed to read Feature_Importance_GDB.csv, trying next source.\", e)\n",
    "\n",
    "# Fallback: Selected_Features_PCC.xlsx\n",
    "if (selected_features is None or len(selected_features) < TOP_K) and os.path.exists(PCC_XLSX):\n",
    "    try:\n",
    "        tmp = pd.read_excel(PCC_XLSX, index_col=0)\n",
    "        cols = [c for c in tmp.columns if c in X_all.columns]\n",
    "        if selected_features is None:\n",
    "            selected_features = cols[:TOP_K]\n",
    "        else:\n",
    "            for c in cols:\n",
    "                if c not in selected_features and len(selected_features) < TOP_K:\n",
    "                    selected_features.append(c)\n",
    "        print(f\"After adding from {PCC_XLSX}, total selected features: {len(selected_features)} (target {TOP_K}).\")\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Failed to read Selected_Features_PCC.xlsx.\", e)\n",
    "\n",
    "# Final fallback: use the first TOP_K columns from X_all\n",
    "if selected_features is None or len(selected_features) < TOP_K:\n",
    "    print(\"⚠️ None of the above sources provided enough features. \"\n",
    "          \"Using the first TOP_K columns (excluding Hv).\")\n",
    "    selected_features = list(X_all.columns[:TOP_K])\n",
    "\n",
    "# Check final feature count\n",
    "if len(selected_features) < TOP_K:\n",
    "    raise ValueError(f\"Final number of selected features < {TOP_K} (current: {len(selected_features)}). \"\n",
    "                     \"Please check naming consistency.\")\n",
    "\n",
    "print(\"\\nFinal 9 features used for modeling:\")\n",
    "for i, f in enumerate(selected_features, 1):\n",
    "    print(f\"{i}. {f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Train-test split\n",
    "# ----------------------------\n",
    "X = X_all[selected_features].to_numpy()\n",
    "y = y_all\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Define model & GridSearchCV\n",
    "# ----------------------------\n",
    "gbr = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 400],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [2, 3, 4, 6],\n",
    "    \"subsample\": [1.0, 0.8, 0.6]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=gbr,\n",
    "    param_grid=param_grid,\n",
    "    cv=CV_FOLDS,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "print(\"\\nStarting GridSearchCV... (this may take a while depending on data size and grid range)\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✅ GridSearch completed. Best parameters:\")\n",
    "print(grid.best_params_)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Evaluate model\n",
    "# ----------------------------\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "metrics = {\n",
    "    \"r2_train\": r2_train,\n",
    "    \"r2_test\": r2_test,\n",
    "    \"rmse_train\": rmse_train,\n",
    "    \"rmse_test\": rmse_test,\n",
    "    \"best_params\": [grid.best_params_]\n",
    "}\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_df.to_csv(OUT_METRICS, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\n✅ Metrics saved to: {OUT_METRICS}\")\n",
    "print(metrics_df.T)\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Save predictions\n",
    "# ----------------------------\n",
    "pred_df_train = pd.DataFrame({\"set\": \"train\", \"y_true\": y_train, \"y_pred\": y_train_pred})\n",
    "pred_df_test = pd.DataFrame({\"set\": \"test\", \"y_true\": y_test, \"y_pred\": y_test_pred})\n",
    "pd.concat([pred_df_train, pred_df_test], ignore_index=True).to_csv(OUT_PREDICTIONS, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ Predictions saved to: {OUT_PREDICTIONS}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Parity plot\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(y_train, y_train_pred, label=f\"Train (R²={r2_train:.3f}, RMSE={rmse_train:.3f})\", alpha=0.7, s=40)\n",
    "plt.scatter(y_test, y_test_pred, label=f\"Test (R²={r2_test:.3f}, RMSE={rmse_test:.3f})\", alpha=0.9, s=60, marker='X')\n",
    "\n",
    "lims = [min(y.min(), y_train.min(), y_test.min(), y_train_pred.min(), y_test_pred.min()),\n",
    "        max(y.max(), y_train.max(), y_test.max(), y_train_pred.max(), y_test_pred.max())]\n",
    "plt.plot(lims, lims, 'k--', linewidth=1)\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.xlabel(\"True Hv\")\n",
    "plt.ylabel(\"Predicted Hv\")\n",
    "plt.title(\"Parity Plot — Gradient Boosting (Top 9 Features)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_PARITY, dpi=300)\n",
    "plt.show()\n",
    "print(f\"✅ Parity plot saved as: {OUT_PARITY}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 8) Bar chart of R² (train vs test)\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(5, 5))\n",
    "labels = [\"Train\", \"Test\"]\n",
    "r2_vals = [r2_train, r2_test]\n",
    "bars = plt.bar(labels, r2_vals, capsize=6)\n",
    "plt.ylim(0, max(1.0, max(r2_vals) * 1.1))\n",
    "plt.ylabel(\"R²\")\n",
    "plt.title(\"R² on Train and Test\")\n",
    "for bar, v in zip(bars, r2_vals):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, v + 0.02, f\"{v:.3f}\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_R2BAR, dpi=300)\n",
    "plt.show()\n",
    "print(f\"✅ R² bar chart saved as: {OUT_R2BAR}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 9) Save model\n",
    "# ----------------------------\n",
    "joblib.dump(grid.best_estimator_, OUT_MODEL)\n",
    "print(f\"✅ Model saved as: {OUT_MODEL}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 10) Save top 9 feature list\n",
    "# ----------------------------\n",
    "pd.DataFrame({\"top_features\": selected_features}).to_csv(\"GDB_top9_features.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ Top 9 feature list saved as: GDB_top9_features.csv\")\n",
    "\n",
    "print(\"\\nAll tasks completed successfully ✅\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
